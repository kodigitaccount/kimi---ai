=================
ðŸ‘‰ Kimi AI by Moonshot AI 
Link: zoom.us/j/87158140121

live streaming== https://www.youtube.com/watch?v=YA9Gf7x91kg
=================


1- https://platform.moonshot.ai/console/api-keys
			Moonshot api key --> 
2- If you install ollama earlier i want you uninstallonce & reinstall one more time 
			google - ollama -- download ollama & install ollama 
			
3- from ollma (download & isntall ) we ran ollama run kimi-k2.5:cloud | we tested in cmd & vs code prompt 

4- kimi k2.5 is already installed in my machine ( i want to build one code) 
		chatbot using kimi 2.5 model 
		
5- groq -- locally by groq api key 
			
	
6- Using groq api key + moonshot kimi k2 model we develope custom chatbot 

7- 

project1 -->  accessed kimi 2.5 from olalma ( locally) 
project2 --> end end to gen ai chatbot using kimi 2 instruct model custom locally 
project3 --> open claw + kimi 2.5 to build telegram bot, whats app 

=== 

code -->
import streamlit as st
from groq import Groq
import os
from dotenv import load_dotenv 

load_dotenv() 

st.set_page_config(page_title="KimiAI Bot", page_icon=":robot_face:", layout="centered")
st.title("KimiAI Bot generated by PRAKASH SENAPATI")
st.caption("power by groq api")

client = Groq(api_key=os.getenv("GROQ-API-KEY")) 

if 'message' not in st.session_state:
    st.session_state['message'] = []
    
for msg in st.session_state.message:
      with st.chat_message(msg["role"]):
            st.markdown(msg["content"])   
            
prompt = st.chat_input("Enter your message here...") 

if prompt:
      st.session_state.message.append({"role": "user", "content": prompt})
      with st.chat_message("user"):
            st.markdown(prompt)
            
      with st.chat_message("assistant"):
            placeholder = st.empty()
            full_response = ""
            
            stream = client.chat.completions.create(
                  model="moonshotai/kimi-k2-instruct-0905",
                  messages=st.session_state.message,
                  max_completion_tokens=2048,
                  temperature=0.7,
                  stream=True
            )
            
      for chunk in stream:
            if(
               chunk.choices
               and chunk.choices[0].delta 
               and chunk.choices[0].delta.content
            ):
               token = chunk.choices[0].delta.content
               full_response += token     
               placeholder.markdown(full_response)
               
      if full_response.strip() != "":
            full_response = "No response from the model"
            
      st.session_state.message.append({"role": "assistant", "content": full_response})   
====
            
                  
           
            
            
             
     
      
      
      



== Kimi AI 

== Openclaw (Part-1) 
https://www.youtube.com/watch?v=QdznP9S1wS0

=== Agentic AI Playlist
https://www.youtube.com/playlist?list=PLVlQHNRLflP8Pt3wVlRWRaXZXi79cIwSq

=======
Follow this link to join my WhatsApp community: 
https://chat.whatsapp.com/DqMB00ggVvRAYdm6EFrX2t


=====NEW BATCH ANNOUNCEMENT=====
Full Stack Data Science with Gen AI & Agentic AI @ 7:00 PM (IST) by Mr.Prakash Senapathi From 09th February
Webinar Link: https://zoom.us/j/82006090582
Registration Link: https://us06web.zoom.us/webinar/register/WN_gWsidGFEQNmtkMh902qqvQ